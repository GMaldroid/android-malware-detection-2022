from collections import Counter
import pickle
import numpy as np
import networkx as nx
import pandas as pd
import gc
import stellargraph as sg
from tensorflow.keras import layers, optimizers, losses, Model # type: ignore 
from sklearn import preprocessing, model_selection
from stellargraph.mapper import GraphSAGENodeGenerator
from stellargraph.layer import GraphSAGE


num_top = 400


def normalize_data(data):
    data = data.to_numpy()
    data = data / (np.amax(data, axis=1) + 0.001)
    data = np.tril(data)
    return data


def load_data_2_create_graph(data_path):
    adj_matr = pd.read_csv(data_path, index_col=None, header=None)
    adj_matr = normalize_data(adj_matr)
    G = nx.Graph(adj_matr)
    del adj_matr
    gc.collect()
    return G


def node_generator(graph_sampled, train_labels, train_targets, val_labels, val_targets, batch_size, num_samples):
    generator = GraphSAGENodeGenerator(graph_sampled, batch_size, num_samples, weighted=True)
    train_gen = generator.flow(train_labels.index, train_targets, shuffle=True)
    val_gen = generator.flow(val_labels.index, val_targets)
    return generator, train_gen, val_gen


G = load_data_2_create_graph(f'../JsonFilesToMatrix/output/top_{num_top}_APIs/m1_{num_top}_APIs.csv')

X = pd.read_csv(f'../JsonFilesToMatrix/output/top_{num_top}_APIs/app_api_{num_top}_APIs_train.csv', header=0, index_col='Unnamed: 0')
labels = X.pop('Label')
labels_sampled = labels.sample(frac=0.8, replace=False, random_state=42)

graph_full = sg.StellarGraph.from_networkx(G, node_features=X)
pickle.dump(graph_full, open(f'output/graph_full_{num_top}.pickle', 'wb'))

graph_sampled = graph_full.subgraph(labels_sampled.index)
pickle.dump(graph_sampled, open(f'output/graph_sampled_{num_top}.pickle', 'wb'))
del G, X

# Split data
train_labels, test_labels = model_selection.train_test_split(
    labels_sampled, train_size=0.6, test_size=None, stratify=labels_sampled, random_state=42,
)
val_labels, test_labels = model_selection.train_test_split(
    test_labels, train_size=0.4, test_size=None, stratify=test_labels, random_state=42,
)

# print(Counter(train_labels))
# print(Counter(val_labels))
# print(Counter(test_labels))

label_encoder = preprocessing.LabelBinarizer().fit(labels)
with open(f'./output/encoder_{num_top}.pkl', 'wb') as f:
    pickle.dump(label_encoder, f)

train_targets = label_encoder.transform(train_labels)
val_targets = label_encoder.transform(val_labels)
test_targets = label_encoder.transform(test_labels)

# Define batch_size, num_samples
batch_size = 50
num_samples = [10, 10]
layer_sizes = [32, 32]
epochs = 60
dropout = 0.2
lr = 0.01

generator, train_gen, val_gen = node_generator(graph_sampled, train_labels, train_targets, val_labels,
                                                        val_targets, batch_size, num_samples)

graphsage_model = GraphSAGE(
    layer_sizes=layer_sizes, generator=generator, bias=True, dropout=dropout,
)

x_inp, x_out = graphsage_model.in_out_tensors()
prediction = layers.Dense(units=5, activation="softmax")(x_out)

model = Model(inputs=x_inp, outputs=prediction)
model.compile(
    optimizer=optimizers.Adam(learning_rate=lr),
    loss=losses.categorical_crossentropy,
    metrics=["acc"],
)

history = model.fit(
    train_gen, epochs=epochs, validation_data=val_gen, verbose=1, shuffle=True
)

model.save_weights(f'output/model_{num_top}.h5')

test_gen = generator.flow(test_labels.index, test_targets)
test_metrics = model.evaluate(test_gen)
print("\nTest Set Metrics:")
for name, val in zip(model.metrics_names, test_metrics):
    print("\t{}: {:0.4f}".format(name, val))

generator_test = GraphSAGENodeGenerator(graph_full, batch_size, num_samples)
hold_out_nodes = labels.index.difference(labels_sampled.index)
labels_hold_out = labels[hold_out_nodes]
hold_out_targets = label_encoder.transform(labels_hold_out)
hold_out_gen = generator_test.flow(hold_out_nodes, hold_out_targets)
hold_out_predictions = model.predict(hold_out_gen)

hold_out_metrics = model.evaluate(hold_out_gen)
print("\nHold Out Set Metrics:")
for name, val in zip(model.metrics_names, hold_out_metrics):
    print("\t{}: {:0.4f}".format(name, val))
