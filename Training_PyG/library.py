import numpy as np
import pandas as pd
import torch
from torch_geometric.data import Data
from torch_geometric.loader import NeighborLoader
from torch.utils.data import random_split


def create_edge_index(node_number):
    index_0 = []
    index_1 = []

    for i in range(node_number):
        index_0.extend([i] * (i + 1))
        index_1.extend(list(range(0, i + 1)))

    return torch.tensor([index_0, index_1])


def create_edge(meta_path):
    adj_mtrx = pd.read_csv(meta_path, index_col=None, header=None)
    node_number = adj_mtrx.shape[0]

    # edge_index
    _edge_index = create_edge_index(node_number)

    # edge_weight
    adj_mtrx = adj_mtrx.to_numpy()
    adj_mtrx = adj_mtrx / (np.amax(adj_mtrx, axis=1) + 0.001)
    adj_mtrx = np.tril(adj_mtrx)

    _edge_weight = []
    for i in range(node_number):
        _edge_weight.extend(adj_mtrx[i, :i + 1])

    return _edge_index, torch.tensor(_edge_weight, dtype=torch.float)


def get_dataset(meta_path, x, y, num_top=400):
    edge_index, edge_weight = create_edge(
        f'../JsonFilesToMatrix/output/top_{num_top}_APIs/{meta_path}_{num_top}_APIs.csv'
    )
    dataset = Data(x=x, y=y, edge_index=edge_index, edge_weight=edge_weight)

    # Saving
    torch.save(dataset, f'./output/full_dataset_{num_top}_{meta_path}.pt')

    torch.manual_seed(42)
    train_dataset, test_dataset = random_split(x, [2400, 600], torch.Generator().manual_seed(42))
    train_mask = [i in train_dataset.indices for i in range(len(dataset.x))]
    test_mask = [i in test_dataset.indices for i in range(len(dataset.x))]
    dataset.test_mask = torch.asarray(test_mask)

    torch.manual_seed(42)
    train_dataset = dataset.subgraph(torch.asarray(train_mask))

    torch.manual_seed(42)
    sub_train_dataset, sub_val_dataset, sub_test_dataset = random_split(
        train_dataset.x, [1440, 384, 576], torch.Generator().manual_seed(42)
    )
    sub_train_mask = [i in sub_train_dataset.indices for i in range(len(train_dataset.x))]
    sub_val_mask = [i in sub_val_dataset.indices for i in range(len(train_dataset.x))]
    sub_test_mask = [i in sub_test_dataset.indices for i in range(len(train_dataset.x))]
    train_dataset.train_mask = torch.asarray(sub_train_mask)
    train_dataset.val_mask = torch.asarray(sub_val_mask)
    train_dataset.test_mask = torch.asarray(sub_test_mask)

    return dataset, train_dataset


def split_batch(dataset, num_neighbors=[10, 20], batch_size=50):
    torch.manual_seed(42)
    train_loader = [data for data in NeighborLoader(data=dataset, input_nodes=dataset.train_mask, num_neighbors=num_neighbors, batch_size=batch_size, directed=True, shuffle=False, num_workers=1)]
    val_loader = [data for data in NeighborLoader(data=dataset, input_nodes=dataset.val_mask, num_neighbors=num_neighbors, batch_size=batch_size, directed=True, shuffle=False, num_workers=1)]
    test_loader = [data for data in NeighborLoader(data=dataset, input_nodes=dataset.test_mask, num_neighbors=num_neighbors, batch_size=batch_size, directed=True, shuffle=False, num_workers=1)]

    return train_loader, val_loader, test_loader


def add_new_nodes(dataset, new_nodes, new_node_label_encodes, x_train):
    number_of_new_nodes = new_nodes.shape[0]
    edge_weight = torch.tensor(new_nodes @ x_train.T)
    self_connections = torch.tensor(new_nodes @ new_nodes.T)
    edge_weight = torch.cat([edge_weight, torch.diagonal(self_connections).reshape(-1, 1)], dim=1)
    max_elements, max_idxs = torch.max(edge_weight, 1)

    edge_weight = torch.div(edge_weight, max_elements.reshape(-1,1) + 0.001)
    edge_weight = edge_weight.flatten()

    new_node_index_start = dataset.edge_index.max().item() + 1
    index_0 = []
    index_1 = []
    for i in range(number_of_new_nodes):
        index_0.extend([new_node_index_start + i] * (new_node_index_start + 1))
        index_1.extend(list(range(0, new_node_index_start)) + [new_node_index_start + i])

    edge_index = torch.tensor([index_0, index_1])

    # add new nodes to graph dataset
    dataset.x = torch.cat([dataset.x, torch.from_numpy(new_nodes).float()], dim=0)
    dataset.edge_index = torch.cat([dataset.edge_index, edge_index], dim=1)
    dataset.edge_weight = torch.cat([dataset.edge_weight, edge_weight], dim=-1)
    dataset.y = torch.cat([dataset.y, new_node_label_encodes], dim=-1)

    return new_node_index_start, dataset
